{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['data']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "6d0b4fa3b8b320d4cb6761c1044de9eb4c3437a1"
      },
      "cell_type": "markdown",
      "source": "## Ακολουθεί κώδικας από προηγούμενα notebooks"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import copy\nimport gzip\nimport torch\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import SubsetRandomSampler, DataLoader\n\ndef torch_train_val_split(\n        dataset, batch_train, batch_eval,\n        val_size=.2, test_size=.3, shuffle=True, seed=42): # We defined an extra parameter test_size in order to create a labeled test set (from the train data)\n    # Creating data indices for training and validation splits:\n    dataset_size = len(dataset)\n    indices = list(range(dataset_size))\n    val_split = int(np.floor(val_size * dataset_size))\n    test_split = int(np.floor(test_size * val_split))\n    if shuffle:\n        np.random.seed(seed)\n        np.random.shuffle(indices)\n    \n    train_indices = indices[val_split:]\n    val_indices = indices[:val_split]\n    test_indices = val_indices[:test_split]\n    val_indices = val_indices[test_split:]\n    \n    # Creating PT data samplers and loaders:\n    train_sampler = SubsetRandomSampler(train_indices)\n    val_sampler = SubsetRandomSampler(val_indices)\n    test_sampler = SubsetRandomSampler(test_indices)\n\n    train_loader = DataLoader(dataset,\n                              batch_size=batch_train,\n                              sampler=train_sampler)\n    val_loader = DataLoader(dataset,\n                            batch_size=batch_eval,\n                            sampler=val_sampler)\n    test_loader = DataLoader(dataset,\n                            batch_size=batch_eval,\n                            sampler=test_sampler)\n    \n    return train_loader, val_loader, test_loader\n\n\ndef read_spectrogram(spectrogram_file, chroma=True):\n    with gzip.GzipFile(spectrogram_file, 'r') as f:\n        spectrograms = np.load(f)\n    # spectrograms contains a fused mel spectrogram and chromagram\n    # Decompose as follows\n    return spectrograms.T\n\n\nclass LabelTransformer(LabelEncoder):\n    def inverse(self, y):\n        try:\n            return super(LabelTransformer, self).inverse_transform(y)\n        except:\n            return super(LabelTransformer, self).inverse_transform([y])\n\n    def transform(self, y):\n        try:\n            return super(LabelTransformer, self).transform(y)\n        except:\n            return super(LabelTransformer, self).transform([y])\n\n        \nclass PaddingTransform(object):\n    def __init__(self, max_length, padding_value=0):\n        self.max_length = max_length\n        self.padding_value = padding_value\n\n    def __call__(self, s):\n        if len(s) == self.max_length:\n            return s\n\n        if len(s) > self.max_length:\n            return s[:self.max_length]\n\n        if len(s) < self.max_length:\n            s1 = copy.deepcopy(s)\n            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n            s1 = np.vstack((s1, pad))\n            return s1\n\n        \nclass SpectrogramDataset(Dataset):\n    def __init__(self, path, class_mapping=None, train=True, max_length=-1):\n        self.train = train\n        t = 'train' if train else 'test'\n        p = os.path.join(path, t)\n        if train:\n            self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n            self.files, self.labels = self.get_files_labels(self.index, class_mapping)\n            self.feats = [read_spectrogram(os.path.join(p, f)) for f in self.files]\n            self.feat_dim = self.feats[0].shape[1]\n            self.lengths = [len(i) for i in self.feats]\n            self.max_length = max(self.lengths) if max_length <= 0 else max_length\n            self.zero_pad_and_stack = PaddingTransform(self.max_length)\n            self.label_transformer = LabelTransformer()\n            self.labels = np.array(self.labels)\n        else: # the labels for the test dataset were not provided\n            self.files = [f for f in os.listdir('../input/data/data/multitask_dataset_beat/test')]\n            self.ids = [int(str(f).rstrip().split('.')[0]) for f in self.files]\n            self.feats = [read_spectrogram(os.path.join('../input/data/data/multitask_dataset_beat/test', f)) for f in self.files]\n            self.feat_dim = self.feats[0].shape[1]\n            self.lengths = [len(i) for i in self.feats]\n            self.max_length = max(self.lengths) if max_length <= 0 else max_length\n            self.zero_pad_and_stack = PaddingTransform(self.max_length)\n\n\n    def get_files_labels(self, txt, class_mapping): # slightly changed (split with comma, labels now contain 3 floats)\n        with open(txt, 'r') as fd:\n            lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]\n        files, labels = [], []\n        for l in lines:\n            label = [float(l[1]), float(l[2]), float(l[3])]\n            files.append(l[0] + '.fused.full.npy.gz')\n            labels.append(label)\n        return files, labels\n\n    def __getitem__(self, item):\n        if self.train:\n            l = min(self.lengths[item], self.max_length)\n            return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n        else:\n            return self.ids[item], self.zero_pad_and_stack(self.feats[item]) # there are no labels for competition data\n        \n    def __len__(self):\n        return len(self.files) # slightly changed\n      \nif __name__ == '__main__':\n    specs = SpectrogramDataset('../input/data/data/multitask_dataset_beat', train=True, max_length=-1)\n    train_loader, val_loader, test_loader = torch_train_val_split(specs, 32 ,32, val_size=.4)\n    competition = DataLoader(SpectrogramDataset('../input/data/data/multitask_dataset_beat', train=False, max_length=-1))\n    #test_specs = [read_spectrogram(os.path.join('../input/data/data/multitask_dataset_beat/test', f))for f in os.listdir('../input/data/data/multitask_dataset_beat/test')]",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "058adad31dd4655482eb4570c6c2771fbbd3ef31"
      },
      "cell_type": "markdown",
      "source": "# Resnet\n## Στα παρακάτω υλοποιούμε ένα basic transfer learning, μέσω των pretrained models που παρέχει το torchvision.\n### Πιο συγκεκριμένα, αλλάξαμε λίγο το τελευταίο στάδιο του δικτύου ώστε να υπολογίζει μία τιμή για κάθε sample και ορίσαμε να αλλάξουν τα βάρη μονάχα αυτόυ του layer, ώστε να γίνει το feature extraction απ' το pretrained model. Επίσης, μιας και το resnet δέχεται είσοδο $224 \\times 224, 3$ καναλιων, κάπως αυθαίρετα κάναμε expand τα features σε τόσες διαστάσεις με μηδενικά (εξ' ου και ο προσδιορισμός basic) και επανάβαμε την ίδια εικόνα και στα 3 κανάλια. Εναλλακτικά, θα μπορούσαμε να κάνουμε κάποιο πιο έξυπνο oversample ή ακόμα καλύτερα να ορίσουμε ένα CNN με έξοδο 3 κανάλια κατάλληλων διαστάσεων και να το εκπαιδεύσουμε και αυτό κατά το fine tuning (δεν υλοποιήθηκε). Χρησημοποιήσαμε την δοκιμασμένη απ' τα προηγούμενα notebooks Smooth L1 Loss που φαίνεται να λειτουργεί καλύτερα για το συγκεκριμένo task. Στόχος της εκπαίδευσης είναι το regression στον άξονα του valency, δηλαδή αυτόν με τις χειρότερες επιδόσεις στην μέθοδ με τα CNNs. Ένα κομμάτι του κώδικα βασίζεται στο [tutorial](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html) ."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "227f0d705da651da916a909047902cb3f27c7a27"
      },
      "cell_type": "code",
      "source": "import torch.nn as nn\ntorch.set_default_tensor_type(torch.DoubleTensor)\nimport scipy.stats as scp\n\ndef evalCNN(model, loss_function, data_loader, axis, test=False):\n    valscores = gold = torch.tensor([])\n    ValLoss = 0\n    model.eval()\n    for feats, labels, lens in data_loader:\n        with torch.no_grad():\n            feats = feats.view(feats.shape[0], 1, feats.shape[2], feats.shape[1])\n            feats = feats.expand(-1, 3, -1, -1)\n            feats_c = torch.zeros(feats.shape[0], 3, 224, 224)\n            feats_c[:, :, :feats.shape[2], :feats.shape[3]] = feats\n            scores = model(feats_c)\n            valscores = torch.cat((valscores, scores.view(-1)))\n            gold = torch.cat((gold, labels[:,axis]))\n            if test==True and ValLoss==0: # print the 1st batch\n                plt.plot(labels[:,axis].numpy(), 'ro', scores.view(-1).numpy(), 'x')\n                plt.ylim(0, 1)\n                plt.show()\n            ValLoss += loss_function(scores.view(-1), labels[:,axis])\n    metric, _ = scp.spearmanr(valscores.detach().numpy(), gold)\n    \n    return metric, ValLoss\n            \ndef trainCNN(model, loss_function, optimizer, epochs, axis):\n    best_metric = 0\n    for epoch in range(epochs):\n        model.train()\n        TrainLoss = 0\n        for feats, labels, lens in (train_loader):\n            # Step 1. Remember that Pytorch accumulates gradients.\n            # We need to clear them out before each instance\n            model.zero_grad()\n            optimizer.zero_grad()\n\n            # Step 3. Run our forward pass.\n            feats = feats.view(feats.shape[0], 1, feats.shape[2], feats.shape[1])\n            feats = feats.expand(-1, 3, -1, -1)\n            #print(feats.shape)\n            feats_c = torch.zeros(feats.shape[0], 3, 224, 224)\n            #print(feats_c.shape)\n            feats_c[:, :, :feats.shape[2], :feats.shape[3]] = feats\n            pred_labels = model(feats_c)\n\n            # Step 4. Compute the loss, gradients, and update the parameters by\n            #  calling optimizer.step()\n            loss = loss_function(pred_labels.view(-1), labels[:,axis])\n            TrainLoss += loss\n            loss.backward()\n            optimizer.step()\n        \n        metric, ValLoss = evalCNN(model, loss_function, val_loader, axis)\n        print(\"Epoch: \" + str(epoch) + \" || train loss: \" + str(TrainLoss) + \" & val loss: \" + str(ValLoss))\n        print(\"Metric is: \" + str(metric))\n        if metric > best_metric:\n            best_metric = metric\n            best_model = copy.deepcopy(model)\n            \n    return best_model",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27bc05b7afa933ad10f17a1fa5ee17c72d8224a9"
      },
      "cell_type": "code",
      "source": "from torchvision import models\n\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False\n\ncheat_model = models.resnet18(pretrained=True)\nset_parameter_requires_grad(cheat_model, True)\ncheat_model.fc = nn.Linear(512, 1)\n\nparams_to_update = cheat_model.parameters()\nprint(\"Params to learn:\")\nif True:\n    params_to_update = []\n    for name,param in cheat_model.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    for name,param in cheat_model.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\noptimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\nloss_function = nn.MSELoss()\ncheatcode = trainCNN(cheat_model, loss_function, optimizer, 5, 0)\n\nmetric, _ = evalCNN(cheat_model, loss_function, test_loader, 0, test=True)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Params to learn:\n\t fc.weight\n\t fc.bias\nEpoch: 0 || train loss: tensor(3.8427, grad_fn=<AddBackward0>) & val loss: tensor(1.4955)\nMetric is: 0.0020979586813876655\nEpoch: 1 || train loss: tensor(1.9165, grad_fn=<AddBackward0>) & val loss: tensor(1.0355)\nMetric is: 0.05695982045818336\nEpoch: 2 || train loss: tensor(1.5437, grad_fn=<AddBackward0>) & val loss: tensor(0.9960)\nMetric is: 0.09349356634212452\nEpoch: 3 || train loss: tensor(1.3101, grad_fn=<AddBackward0>) & val loss: tensor(1.1214)\nMetric is: 0.11941290104248699\nEpoch: 4 || train loss: tensor(1.4607, grad_fn=<AddBackward0>) & val loss: tensor(0.9897)\nMetric is: 0.1394649284800014\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}